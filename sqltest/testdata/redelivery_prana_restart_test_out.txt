use test;
0 rows returned
--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col0)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "json",
    valueencoding = "json",
    columnselectors = (
        meta("key").k0,
        v1,
        v2,
        v3,
        v4,
        v5,
        v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);
0 rows returned

--load data dataset_1;
select * from test_source_1 order by col0;
+---------------------------------------------------------------------------------------------------------------------+
| col0                 | col1 | col2        | col3         | col4         | col5         | col6                       |
+---------------------------------------------------------------------------------------------------------------------+
| 1                    | 10   | 1000        | 1234.4321    | 12345678.99  | str1         | 2020-01-01 01:00:00.123456 |
| 2                    | 20   | 2000        | 2234.4321    | 22345678.99  | str2         | 2020-01-02 01:00:00.123456 |
| 3                    | 30   | 3000        | 3234.4321    | 32345678.99  | str3         | 2020-01-03 01:00:00.123456 |
| 4                    | 40   | 4000        | 4234.4321    | 42345678.99  | str4         | 2020-01-04 01:00:00.123456 |
| 5                    | 50   | 5000        | 5234.4321    | 52345678.99  | str5         | 2020-01-05 01:00:00.123456 |
| 6                    | 60   | 6000        | 6234.4321    | 62345678.99  | str6         | 2020-01-06 01:00:00.123456 |
| 7                    | 70   | 7000        | 7234.4321    | 72345678.99  | str7         | 2020-01-07 01:00:00.123456 |
| 8                    | 80   | 8000        | 8234.4321    | 82345678.99  | str8         | 2020-01-08 01:00:00.123456 |
| 9                    | 90   | 9000        | 9234.4321    | 92345678.99  | str9         | 2020-01-09 01:00:00.123456 |
| 10                   | 100  | 10000       | 10234.4321   | 93345678.99  | str10        | 2020-01-10 01:00:00.123456 |
+---------------------------------------------------------------------------------------------------------------------+
10 rows returned

-- We delete the topic, then recreate, then load it with messages with the same id (from 1-10) but different other fields
-- We then restart the cluster - the first 10 messages should be ignored due to duplicate detection as they will have the
-- same offsets;
--delete topic testtopic;
--create topic testtopic;
--restart cluster;

use test;
0 rows returned

--load data dataset_2;
--wait for committed test_source_1 15;
select * from test_source_1 order by col0;
+---------------------------------------------------------------------------------------------------------------------+
| col0                 | col1 | col2        | col3         | col4         | col5         | col6                       |
+---------------------------------------------------------------------------------------------------------------------+
| 1                    | 10   | 1000        | 1234.4321    | 12345678.99  | str1         | 2020-01-01 01:00:00.123456 |
| 2                    | 20   | 2000        | 2234.4321    | 22345678.99  | str2         | 2020-01-02 01:00:00.123456 |
| 3                    | 30   | 3000        | 3234.4321    | 32345678.99  | str3         | 2020-01-03 01:00:00.123456 |
| 4                    | 40   | 4000        | 4234.4321    | 42345678.99  | str4         | 2020-01-04 01:00:00.123456 |
| 5                    | 50   | 5000        | 5234.4321    | 52345678.99  | str5         | 2020-01-05 01:00:00.123456 |
| 6                    | 60   | 6000        | 6234.4321    | 62345678.99  | str6         | 2020-01-06 01:00:00.123456 |
| 7                    | 70   | 7000        | 7234.4321    | 72345678.99  | str7         | 2020-01-07 01:00:00.123456 |
| 8                    | 80   | 8000        | 8234.4321    | 82345678.99  | str8         | 2020-01-08 01:00:00.123456 |
| 9                    | 90   | 9000        | 9234.4321    | 92345678.99  | str9         | 2020-01-09 01:00:00.123456 |
| 10                   | 100  | 10000       | 10234.4321   | 93345678.99  | str10        | 2020-01-10 01:00:00.123456 |
| 11                   | 112  | 11000       | 11234.4321   | 62345678.99  | str6         | 2020-01-06 01:00:00.123456 |
| 12                   | 113  | 12000       | 12234.4321   | 72345678.99  | str7         | 2020-01-07 01:00:00.123456 |
| 13                   | 114  | 13000       | 13234.4321   | 82345678.99  | str8         | 2020-01-08 01:00:00.123456 |
| 14                   | 115  | 14000       | 14234.4321   | 92345678.99  | str9         | 2020-01-09 01:00:00.123456 |
| 15                   | 116  | 15000       | 15234.4321   | 93345678.99  | str10        | 2020-01-10 01:00:00.123456 |
+---------------------------------------------------------------------------------------------------------------------+
15 rows returned

drop source test_source_1;
0 rows returned
--delete topic testtopic;
