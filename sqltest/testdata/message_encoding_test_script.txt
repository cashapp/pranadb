-- We test various different ways of encoding kafka messages with keys, values, headers JSON and binary etc;

-- TEST1 - string encoded key, top level JSON encoded value;

--create topic testtopic;

use test;

create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col5)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "stringbytes",
    valueencoding = "json",
    columnselectors = (
        v0,
        v1,
        v2,
        v3,
        v4,
        meta("key"),
        v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_1;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST2 - int64BE encoded key, top level JSON encoded value;
------------------------------------------------------------;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col0)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "int64be",
    valueencoding = "json",
    columnselectors = (
        meta("key"),
        v1,
        v2,
        v3,
        v4,
        v5,
        v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_2;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST3 - int32BE encoded key, top level JSON encoded value;
------------------------------------------------------------;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col2)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "int32be",
    valueencoding = "json",
    columnselectors = (
        v0,
        v1,
        meta("key"),
        v3,
        v4,
        v5,
        v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_3;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST4 - float64BE encoded key, top level JSON encoded value;
--------------------------------------------------------------;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col3)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "float64be",
    valueencoding = "json",
    columnselectors = (
        v0,
        v1,
        v2,
        meta("key"),
        v4,
        v5,
        v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_4;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST5 - float32BE encoded key, top level JSON encoded value;
--------------------------------------------------------------;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col3)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "float32be",
    valueencoding = "json",
    columnselectors = (
        v0,
        v1,
        v2,
        meta("key"),
        v4,
        v5,
        v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_5;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST6 - int16BE encoded key, top level JSON encoded value;
--------------------------------------------------------------;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col2)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "int16be",
    valueencoding = "json",
    columnselectors = (
        v0,
        v1,
        meta("key"),
        v3,
        v4,
        v5,
        v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_6;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST7 - top level JSON encoded key, top level JSON encoded value;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col0)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "json",
    valueencoding = "json",
    columnselectors = (
        meta("key").k0,
        v1,
        v2,
        v3,
        v4,
        v5,
        v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_7;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST8 - nested JSON encoded key, nested JSON encoded value;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col0)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "json",
    valueencoding = "json",
    columnselectors = (
        meta("key").n0.k0,
        n1.v1,
        n2.v2,
        n3.v3,
        n4.v4,
        n5.v5,
        n6.v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_8;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST9 - key and value encoded as message headers in JSON!;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col0)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "json",
    valueencoding = "json",
    columnselectors = (
        meta("header").key.k0,
        meta("header").val.v1,
        meta("header").val.v2,
        meta("header").val.v3,
        meta("header").val.v4,
        meta("header").val.v5,
        meta("header").val.v6
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_9;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST10 - timestamp column value coming from timestamp of Kafka message;

--create topic testtopic;
create source test_source_1(
    col0 bigint,
    col1 tinyint,
    col2 int,
    col3 double,
    col4 decimal(10, 2),
    col5 varchar,
    col6 timestamp(6),
    primary key (col0)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "json",
    valueencoding = "json",
    columnselectors = (
        meta("key").k0,
        v1,
        v2,
        v3,
        v4,
        v5,
        meta("timestamp")
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_10;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;

-- TEST11 - protobuf message;

--create topic testtopic;
create source test_source_1(
    col0 double,
    col1 double,
    col2 int,
    col3 bigint,
    col4 int,
    col5 bigint,
    col6 tinyint,
    col7 varchar,
    col8 int,
    col9 varchar,
    primary key (col7)
) with (
    brokername = "testbroker",
    topicname = "testtopic",
    headerencoding = "json",
    keyencoding = "stringbytes",
    valueencoding = "protobuf:squareup.cash.pranadb.testproto.v1.TestTypes",
    columnselectors = (
        double_field,
        float_field,
        int32_field,
        int64_field,
        uint32_field,
        uint64_field,
        bool_field,
        meta("key"),
        enum_field,
        enum_field
    ),
    properties = (
        "prop1" = "val1",
        "prop2" = "val2"
    )
);

--load data dataset_11;

select * from test_source_1 order by col0;

drop source test_source_1;

--delete topic testtopic;
